{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "jqe2s4d6o5klmbgvcpmc",
   "authorId": "4666429640372",
   "authorName": "APOWOPA",
   "authorEmail": "220300773@ucaribe.edu.mx",
   "sessionId": "f110d7ac-8b29-4947-9b58-d16561193dc1",
   "lastEditTime": 1758298012992
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39b9a871-6a30-4786-969e-f8b959287e13",
   "metadata": {
    "name": "cell6",
    "collapsed": false
   },
   "source": "# TAREA 3 - ETL DATASET BI\n\n## INTEGRANTES:\n- Apolonio Cuevas Manuel Alberto\n- Sansores Arjona Alejandro Jesus\n- Israel Alejandro Cel Alcocer\n- Salvador Iram Salas Baez\n- Leo Sebastian Contreras Raymund"
  },
  {
   "cell_type": "markdown",
   "id": "ebd4585e-9562-41cf-8bcc-f0e280a2a67c",
   "metadata": {
    "name": "cell7",
    "collapsed": false
   },
   "source": " ## Configuracion del Ambiente\n"
  },
  {
   "cell_type": "code",
   "id": "b3874620-53d9-4ba4-a28b-854766ca5c1b",
   "metadata": {
    "language": "sql",
    "name": "cell5",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "---> set the Role\nUSE ROLE SNOWFLAKE_LEARNING_ROLE;\n---> set the Warehouse\nUSE WAREHOUSE SNOWFLAKE_LEARNING_WH;\n\nUSE DATABASE INFO_EMPLEADOS;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "21f809b1-0b59-42af-b55c-7140f20f0f9b",
   "metadata": {
    "language": "python",
    "name": "cell12"
   },
   "outputs": [],
   "source": "import toml\nfrom snowflake.snowpark.session import Session\n\n# Ruta al archivo connections.toml dentro del stage del notebook\n# Nota: La ruta es relativa al stage, por lo general es el nombre del archivo.\nconnections_file_path = \"connections.toml\"\n\n# Leer el archivo TOML y cargar las configuraciones\ntry:\n    with open(connections_file_path, \"r\") as f:\n        config = toml.load(f)\n    print(\"Archivo connections.toml cargado exitosamente.\")\nexcept FileNotFoundError:\n    print(f\"Error: El archivo {connections_file_path} no fue encontrado.\")\n    config = None\n\n# Crear la sesión si el archivo se cargó correctamente\nif config:\n    try:\n        session = Session.builder.configs(config).create()\n        print(\"Sesión de Snowflake creada exitosamente.\")\n    except Exception as e:\n        print(f\"Error al crear la sesión: {e}\")\nelse:\n    print(\"No se puede crear la sesión debido a un error en la carga de la configuración.\")\n\n# Opcional: Mostrar detalles de la sesión\nif 'session' in locals():\n    print(\"Database:\", session.get_current_database())\n    print(\"Schema:\", session.get_current_schema())\n    print(\"Warehouse:\", session.get_current_warehouse())\n    print(\"Role\",session.get_current_role())",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1b6bcd59-9b1b-448c-8739-faff81b9149f",
   "metadata": {
    "language": "python",
    "name": "cell8"
   },
   "outputs": [],
   "source": "# Import python packages\nimport snowflake.snowpark.types as T\nimport snowflake.snowpark.functions as F\nfrom snowflake.snowpark import Session\n\nsession = Session.builder.config(\"connection_name\", \"myconnection\").create()\n\nprint(session)",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b0f2a3f9-5145-478f-b31c-cfcbb962ad4c",
   "metadata": {
    "name": "cell9",
    "collapsed": false
   },
   "source": "### Cargo de datos en la tabla"
  },
  {
   "cell_type": "code",
   "id": "e28b92d8-6d1e-4e27-a9cb-822f5198e0b3",
   "metadata": {
    "language": "python",
    "name": "cell11"
   },
   "outputs": [],
   "source": "# Importar la librería de Snowpark\nimport snowflake.snowpark as snowpark\nfrom snowflake.snowpark.functions import col\nfrom snowflake.snowpark.context import get_active_session\n\n# 1. Obtener la sesión activa de Snowpark (¡esto ya lo tienes y es perfecto!)\nsession = get_active_session()\n\n# 1. Define la tabla de destino\nnombre_tabla = \"TAREA3_RAW\"\n\n# 2. Define la RUTA CORRECTA al archivo en el stage del notebook\n# La ruta debe empezar con @ y los nombres de la base de datos, esquema y notebook van entre comillas.\nstage_path = '@\"INFO_EMPLEADOS\".\"PUBLIC\".\"TAREA3\"/versions/live/bi.csv'\n\n# 3. Lee el archivo CSV desde el stage\ndf = session.read.option(\"encoding\", \"ISO-8859-1\") \\\n                 .option(\"header\", \"true\") \\\n                 .option(\"infer_schema\", \"true\") \\\n                 .csv(stage_path)\n\n# 4. Trunca la tabla y carga los nuevos datos\ndf.write.mode(\"overwrite\").save_as_table(nombre_tabla)\n\n# 5. Muestra una confirmación y una vista previa\nprint(f\"La tabla '{nombre_tabla}' ha sido truncada y cargada con éxito.\")\ndf.show()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "024a86b8-c62e-4d50-9050-a93ce42254d3",
   "metadata": {
    "language": "sql",
    "name": "cell10"
   },
   "outputs": [],
   "source": "TRUNCATE TABLE TAREA3_RAW;\n\nCOPY INTO TAREA3_RAW\nFROM snow://notebook/INFO_EMPLEADOS.PUBLIC.TAREA3/versions/live/bi.csv\nFILE_FORMAT = (TYPE = 'CSV' FIELD_DELIMITER = ',' SKIP_HEADER = 1 ENCODING = 'ISO-8859-1')\nON_ERROR = 'CONTINUE';\n\nSELECT *\nFROM TAREA3_RAW;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c7bb828d-f373-480e-a555-6cfedc132f46",
   "metadata": {
    "language": "python",
    "name": "cell4"
   },
   "outputs": [],
   "source": "import pandas as pd\nimport os\n\ndata = pd.read_csv(\"bi.csv\",encoding=\"latin-1\")\ndata.head()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "python",
    "name": "cell1"
   },
   "source": "import os\nimport json\nfrom snowflake.snowpark.context import get_active_session\n\n# 1. Obtener la sesión activa de Snowpark (¡esto ya lo tienes y es perfecto!)\nsession = get_active_session()\n\n# 2. Cargar las credenciales desde el Snowflake Secret\nkaggle_credentials = session.get_secret_value(\"mi_secreto_kaggle\")\n\n# El secreto es un string JSON, así que lo convertimos a un diccionario de Python\nkaggle_secrets = json.loads(kaggle_credentials)\n\n# 3. Configurar las variables de entorno para la API de Kaggle\nos.environ['KAGGLE_USERNAME'] = kaggle_secrets['username']\nos.environ['KAGGLE_KEY'] = kaggle_secrets['key']\n\n# 4. Conectar a Kaggle (esto no cambia)\nfrom kaggle.api.kaggle_api_extended import KaggleApi\napi = KaggleApi()\napi.authenticate()\n\nprint(\"¡Conexión exitosa a Kaggle usando Snowflake Secrets!\")",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "sql",
    "name": "cell2"
   },
   "source": "-- Welcome to Snowflake Notebooks!\n-- Try out a SQL cell to generate some data.\nSELECT 'FRIDAY' as SNOWDAY, 0.2 as CHANCE_OF_SNOW\nUNION ALL\nSELECT 'SATURDAY',0.5\nUNION ALL \nSELECT 'SUNDAY', 0.9;",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "language": "python",
    "name": "cell3"
   },
   "source": "# Then, we can use the python name to turn cell2 into a Pandas dataframe\nmy_df = cell2.to_pandas()\n\n# Chart the data\nst.subheader(\"Chance of SNOW ❄️\")\nst.line_chart(my_df, x='SNOWDAY', y='CHANCE_OF_SNOW')\n\n# Give it a go!\nst.subheader(\"Try it out yourself and show off your skills 🥇\")",
   "execution_count": null,
   "outputs": []
  }
 ]
}